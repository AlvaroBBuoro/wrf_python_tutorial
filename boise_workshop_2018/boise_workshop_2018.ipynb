{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the WRF-Python and VAPOR Workshop!\n",
    "September 26-27, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Quick Reference\n",
    "\n",
    "**To execute a cell in jupyter notebook**:\n",
    "\n",
    "1. Click on the desired cell.\n",
    "2. Press **CTRL + RETURN** to execute the cell or press **SHIFT + RETURN** to execute the cell and advance to the next cell.\n",
    "3. Alternatively, you can use the Cell dropdown menu\n",
    "\n",
    "**If you accidentally double click on a Markdown Cell (cells with no code, only pretty text)**.\n",
    "\n",
    "You will usually see text, and most likely blue '#' characters and letters\n",
    "1. Simply execute the cell using the instructions above\n",
    "\n",
    "**If you experience a problem and want to restart your notebook**:\n",
    "\n",
    "1. Use the Kernel dropdown menu at the top.\n",
    "2. Execute Kernel -> Restart & Clear Output.\n",
    "3. Be sure the run **Example 1.1: Verifying your Jupyter Environment** before running any \n",
    "   other cells.\n",
    "\n",
    "\n",
    "**Shutting down the notebook**\n",
    "\n",
    "1. On your web browser, select the Home tab.\n",
    "2. Click the check box next to boise_workshop_2018.ipynb.\n",
    "3. Click the Shutdown button that will become available after step 2.\n",
    "4. Now go to the terminal window where you typed in \"jupyter notebook\".\n",
    "5. With the terminal window active, press **CTRL + C**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Introduction to jupyter, numpy, xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.1 Verifying your Jupyter Environment\n",
    "\n",
    "Looking at your own WRF data is much more fun than my examples!  If you have your own data files, during the Open Lab section, do the following:\n",
    "\n",
    "1. Place the WRF output files in to a single directory.  Pick two or three files to limit memory.\n",
    "2. In the cell below, modify the **WRF_DIRECTORY** and **WRF_FILES** variables to point to your data.\n",
    "3. Execute the cell and verify that \"All Tests Passed!\" is printed.\n",
    "4. If not, raise your hand and one of the lab assistants will help.\n",
    "\n",
    "**IMPORTANT: If for some reason your workbook crashes, you need to run this cell again before running the later examples**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# This jupyter notebook command inserts matplotlib graphics in \n",
    "# to the workbook\n",
    "%matplotlib inline\n",
    "\n",
    "# Modify these to point to your own files\n",
    "WRF_DIRECTORY = \"~/wrf_tutorial_data\"\n",
    "WRF_FILES = [\"wrfout_d01_2010-06-02_00_00_00\",\n",
    "             \"wrfout_d01_2010-06-03_00_00_00\",\n",
    "             \"wrfout_d01_2010-06-04_00_00_00\"]\n",
    "\n",
    "\n",
    "# Do not modify the code below this line\n",
    "#------------------------------------------------------\n",
    "# Turn off annoying warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Make sure the environment is good\n",
    "import numpy\n",
    "import cartopy\n",
    "import matplotlib\n",
    "from netCDF4 import Dataset\n",
    "from xarray import DataArray\n",
    "from wrf import (getvar, interplevel, vertcross, \n",
    "                 vinterp, ALL_TIMES)\n",
    "import os\n",
    "\n",
    "_WRF_FILES = [os.path.abspath(os.path.expanduser(\n",
    "    os.path.join(WRF_DIRECTORY, f))) for f in WRF_FILES]\n",
    "\n",
    "# Check that the WRF files exist\n",
    "for f in _WRF_FILES:\n",
    "    if not os.path.exists(f):\n",
    "        raise ValueError(\"{} does not exist. \"\n",
    "            \"Check for typos or incorrect directory.\".format(f))\n",
    "\n",
    "# Create functions so that the WRF files only need\n",
    "# to be specified using the WRF_FILES global above\n",
    "def single_wrf_file():\n",
    "    global _WRF_FILES\n",
    "    return _WRF_FILES[0]\n",
    "\n",
    "def multiple_wrf_files():\n",
    "    global _WRF_FILES\n",
    "    return _WRF_FILES\n",
    "\n",
    "print(\"All tests passed!\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy Way-Too-Quick Reference\n",
    "\n",
    "See https://docs.scipy.org/doc/numpy/user/quickstart.html for a much more complete introduction.\n",
    "\n",
    "## Creating an Array\n",
    "\n",
    "The zeros function creates an array with all 0's.  \n",
    "\n",
    "Begin by specifying the desired shape as a tuple and then specify the data type (Note: \"float32\" is the default if not specified).\n",
    "\n",
    "``` python\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "```\n",
    "\n",
    "## Accessing Elements\n",
    "\n",
    "Use the \"[ ]\" syntax with the desired dimension indexes separated by commas.\n",
    "\n",
    "``` python\n",
    "\n",
    "# Getting an element\n",
    "first_element = my_array[0,0,0]\n",
    "last_element = my_array[-1,-1,-1]\n",
    "mid_element = my_array[1,1,1]\n",
    "\n",
    "# Setting an element\n",
    "my_array[1,1,1] = 10.0\n",
    "\n",
    "```\n",
    "\n",
    "## Slices\n",
    "\n",
    "Use the 'start : end' syntax for slicing.  \n",
    "\n",
    "If *start* is left blank, the slice begins at the start of the array.  \n",
    "\n",
    "If *end* is blank, the slice ends at the end of the array.\n",
    "\n",
    "``` python\n",
    "import numpy\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "first_row = my_array[0,0,:]\n",
    "\n",
    "first_column = my_array[0,:,0]\n",
    "\n",
    "first_z = my_array[:,0,0]\n",
    "\n",
    "subset = my_array[:, :, 1:3]\n",
    "\n",
    "```\n",
    "\n",
    "## MaskedArray\n",
    "\n",
    "Use the *masked_{condition}* functions to create MaskedArray objects.\n",
    "\n",
    "``` python\n",
    "\n",
    "import numpy\n",
    "import numpy.ma\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "# Now all of the array elements are masked values\n",
    "my_masked = numpy.ma.masked_equal(my_array, 0)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.2: Numpy Basics\n",
    "\n",
    "This example demonstrates the basics of creating a numpy array, getting and setting an array element, slicing, and masking values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy.ma\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "print(\"my_array\")\n",
    "print(my_array)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Setting an element\n",
    "my_array[1,1,1] = 10.0\n",
    "\n",
    "# Getting an element\n",
    "mid = my_array[1,1,1]\n",
    "\n",
    "print(\"Mid element set\")\n",
    "print(my_array)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Getting a slice\n",
    "my_slice = my_array[1,:,:]\n",
    "\n",
    "print(\"my_slice\")\n",
    "print(my_slice)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Masking the zeros\n",
    "my_masked = numpy.ma.masked_equal(my_array, 0)\n",
    "\n",
    "print(\"my_masked\")\n",
    "print(my_masked)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xarray Basic Way-Too-Quick Reference\n",
    "\n",
    "See http://xarray.pydata.org/ for a much more complete reference on xarray.\n",
    "\n",
    "## Creating an xarray DataArray\n",
    "\n",
    "\n",
    "Arguments for creating a DataArray are:\n",
    "\n",
    "- data [required]: A numpy array.\n",
    "- coords [optional]: A dictionary of {dimension_name : coordinate_array}.\n",
    "- dims [optional]: A list of dimension names from left to right.\n",
    "- name [optional]: A name for the variable.\n",
    "- attrs[optional]: A dictionary of {attr_name : attr_value}.\n",
    "\n",
    "``` python\n",
    "\n",
    "import numpy\n",
    "import xarray\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "# Making up dimension names and coordinates.\n",
    "my_name = \"my_xarray\"\n",
    "\n",
    "my_dims = [\"bottom_top\", \"south_north\", \"west_east\"]\n",
    "\n",
    "my_coords = {\"bottom_top\" : [100., 200., 300.],\n",
    "             \"south_north\": [40., 50., 60.],\n",
    "             \"west_east\" : [-120., -110., -100.]\n",
    "            }\n",
    "\n",
    "my_attrs = {\"info\" : \"This is my xarray\"}\n",
    "\n",
    "my_xarray = xarray.DataArray(my_array,\n",
    "                             name=my_name,\n",
    "                             dims=my_dims, \n",
    "                             coords=my_coords, \n",
    "                             attrs=my_attrs)\n",
    "\n",
    "```\n",
    "\n",
    "## xarray Arrays with Missing Values\n",
    "\n",
    "- xarray always uses NaN for missing values.\n",
    "- This can cause problems with compiled math rouines.\n",
    "- The xarray.DataArray contains a .values property to get the numpy array, but this will not \n",
    "  replace the NaN values with the _FillValue values (see fillna and to_masked_array in xarray documentation).\n",
    "- wrf-python has a *to_np* function that will handle the conversion to numpy for you and fill in the missing values if _FillValue is in the attributes.\n",
    "\n",
    "## xarray Notes:\n",
    "\n",
    "- xarray DataArrays support most of the numpy methods and attributes, but not all.\n",
    "- xarray DataArrays are NOT numpy subclasses.  \n",
    "- Often you need to extract the numpy array from the DataArray before passing the array to \n",
    "  a computational routine.\n",
    "- However, the routines in wrf-python are xarray-aware and will do this for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.3: Creating an xarray DataArray\n",
    "\n",
    "Run the cell below to see what an xarray DataArray looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import xarray\n",
    "\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "# Making up dimension names and coordinates.\n",
    "my_name = \"my_xarray\"\n",
    "\n",
    "my_dims = [\"bottom_top\", \"south_north\", \"west_east\"]\n",
    "\n",
    "my_coords = {\"bottom_top\" : [100., 200., 300.],\n",
    "             \"south_north\": [40., 50., 60.],\n",
    "             \"west_east\" : [-120., -110., -100.]\n",
    "            }\n",
    "\n",
    "my_attrs = {\"info\" : \"This is my xarray\"}\n",
    "\n",
    "my_xarray = xarray.DataArray(my_array,\n",
    "                             name=my_name,\n",
    "                             dims=my_dims, \n",
    "                             coords=my_coords, \n",
    "                             attrs=my_attrs)\n",
    "\n",
    "print(my_xarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2.4: xarray and Missing Values\n",
    "\n",
    "In this example, an xarray.DataArray is constructed from a MaskedArray.  \n",
    "\n",
    "Note how the missing values are all NaN.\n",
    "\n",
    "At the end, the wrf-python *to_np* routine is used to convert the DataArray back to a MaskedArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy.ma\n",
    "import xarray\n",
    "\n",
    "from wrf import to_np\n",
    "\n",
    "# Create a MaskedArray with 10.0 in the center\n",
    "my_array = numpy.zeros((3,3,3), \"float32\")\n",
    "\n",
    "my_array[1,1,1] = 10.0\n",
    "\n",
    "my_masked = numpy.ma.masked_equal(my_array, 0)\n",
    "\n",
    "# Making up dimension names and \n",
    "# coordinates.\n",
    "my_name = \"my_masked_xarray\"\n",
    "\n",
    "my_dims = [\"bottom_top\", \"south_north\", \"west_east\"]\n",
    "\n",
    "my_coords = {\"bottom_top\" : [100., 200., 300.],\n",
    "             \"south_north\": [40., 50., 60.],\n",
    "             \"west_east\" : [-120., -110., -100.]\n",
    "            }\n",
    "\n",
    "my_attrs = {\"info\" : \"This is my masked xarray\",\n",
    "           \"_FillValue\" : -999.0}\n",
    "\n",
    "# Create the xarray DataArray\n",
    "my_xarray = xarray.DataArray(my_masked,\n",
    "                             name=my_name,\n",
    "                             dims=my_dims, \n",
    "                             coords=my_coords, \n",
    "                             attrs=my_attrs)\n",
    "\n",
    "print(\"xarray Array with Missing Values\")\n",
    "print(my_xarray)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Covert back to a MaskedArray\n",
    "converted = to_np(my_xarray)\n",
    "\n",
    "print(\"Converted to a MaskedArray with to_np\")\n",
    "print(converted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.0 Overview of WRF-ARW Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3.1: Running ncdump\n",
    "\n",
    "In this example, the ncdump command is called from inside of python.  \n",
    "\n",
    "Examine the output for your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "# This simply executes 'ncdump -h {wrf_file}' \n",
    "# from Python\n",
    "p = Popen([\"ncdump\", \"-h\", \"{}\".format(file_path)], stdout=PIPE, stderr=STDOUT)\n",
    "output, _ = p.communicate()\n",
    "\n",
    "print(output.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 3.2: Using netcdf4-python\n",
    "\n",
    "In this example, the netcdf4-python package is used to read your WRF NetCDF file.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "print(wrf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 3.3: Variables, Attributes, and Data with netcd4-python\n",
    "\n",
    "In this example, netcdf4-python is used to get the global attributes, get a variable (P), get the variable attributes (coordinates), and get the variable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "# Create the netCDF4.Dataset object\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get the global attribute dict\n",
    "global_attrs = wrf_file.__dict__\n",
    "print(\"Global attributes for the file\")\n",
    "print(global_attrs)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Just get the 'MAP_PROJ' attribute\n",
    "map_proj = wrf_file.getncattr(\"MAP_PROJ\")\n",
    "print(\"The MAP_PROJ attribute:\")\n",
    "print(map_proj)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Get the perturbation pressure variable\n",
    "p = wrf_file.variables[\"P\"]\n",
    "print(\"The P variable: \")\n",
    "print(p)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Get the P attributes\n",
    "p_attrs = p.__dict__\n",
    "print(\"The attribute dict for P\")\n",
    "print(p_attrs)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Get the 'coordinates' attribute for P\n",
    "coords = p.getncattr(\"coordinates\")\n",
    "print(\"Coordinates for P:\")\n",
    "print(coords)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Get the P numpy array for all times\n",
    "p_all_data = p[:]\n",
    "print(\"The P numpy array: \")\n",
    "print(p_all_data)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Get the P numpy array for time 0\n",
    "p_t0_data = p[0,:]\n",
    "print(\"P array at time 0:\")\n",
    "print(p_t0_data)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4.0 WRF-Python Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4.1: Using getvar to Extract a WRF NetCDF Variable\n",
    "\n",
    "In this example, the *getvar* function is used to read a variable in a WRF NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "hgt = getvar(wrf_file, \"HGT\", timeidx=0)\n",
    "\n",
    "print(hgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 4.2: Using getvar to compute Sea Level Pressure (SLP)\n",
    "\n",
    "In this example, *getvar* is used to compute a diagnostic variable.\n",
    "\n",
    "The full table of avaiable diagnostics is here:  http://wrf-python.readthedocs.io/en/latest/diagnostics.html\n",
    "\n",
    "Also try changing the units for by specifiying the following values: 'hPa', 'Pa', 'atm', 'mmhg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "slp = getvar(wrf_file, \"slp\", timeidx=0, units=\"hPa\")\n",
    "\n",
    "print(slp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 4.3: Combining Files Using the 'cat' Method\n",
    "\n",
    "In this example, the variable is computed for all times, across all files, and combined along the Time dimension by using the 'cat' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, ALL_TIMES\n",
    "\n",
    "file_paths = multiple_wrf_files()\n",
    "wrf_files = [Dataset(f) for f in file_paths]\n",
    "\n",
    "slp = getvar(wrf_files, \"slp\", timeidx=ALL_TIMES, method=\"cat\")\n",
    "\n",
    "print(slp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 4.4: Combining Files Using the 'join' Method\n",
    "\n",
    "In this example, the variable is computed for all times, across all files, and combined by creating a new leftmost index for the file by using the 'join' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, ALL_TIMES\n",
    "\n",
    "file_paths = multiple_wrf_files()\n",
    "wrf_files = [Dataset(f) for f in file_paths]\n",
    "\n",
    "slp = getvar(wrf_files, \"slp\", timeidx=ALL_TIMES, method=\"join\")\n",
    "\n",
    "print(slp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 4.5: Interpolate to 500 hPa Using interplevel\n",
    "\n",
    "In this example, the 500 hPa geopotential heights are calculated by using the *interplevel* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, interplevel\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "pres = getvar(wrf_file, \"pressure\", timeidx=0)\n",
    "ht = getvar(wrf_file, \"z\", timeidx=0, units=\"dm\")\n",
    "\n",
    "ht_500 = interplevel(ht, pres, 500.0)\n",
    "\n",
    "print(ht_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 4.6: Interpolate to a Vertical Cross Section with vertcross\n",
    "\n",
    "In this example, the vertical cross section for wind speed is calculated using the *vertcross* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, vertcross, CoordPair\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Making a diagonal cross section line from \n",
    "# bottom left to top right.\n",
    "bottom_left = CoordPair(x=0, y=0)\n",
    "top_right = CoordPair(x=-1, y=-1)\n",
    "\n",
    "# Let's get wind speed in kts\n",
    "wspd_wdir = getvar(wrf_file, \"wspd_wdir\", \n",
    "                   timeidx=0, units=\"kt\")          \n",
    "wspd = wspd_wdir[0,:]\n",
    "\n",
    "# Get the height levels\n",
    "ht = getvar(wrf_file, \"z\", timeidx=0)\n",
    "\n",
    "wspd_cross = vertcross(wspd, ht, \n",
    "                       start_point=bottom_left, \n",
    "                       end_point=top_right, latlon=True)\n",
    "\n",
    "print(wspd_cross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 4.7: Interpolate to Theta-e Levels with vinterp\n",
    "\n",
    "In this example, pressure is interpolated to various theta-e levels by using the *vinterp* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, vinterp \n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path) \n",
    "\n",
    "pres = getvar(wrf_file, \"pressure\", timeidx=0)\n",
    "\n",
    "# Interpolate pressure to theta-e levels                 \n",
    "interp_levels = [280., 285., 290., 292., 294., \n",
    "                 296., 298., 300., 305., 310.]\n",
    "\n",
    "pres_eth = vinterp(wrf_file, \n",
    "                   field=pres, \n",
    "                   vert_coord=\"theta-e\", \n",
    "                   interp_levels=interp_levels, \n",
    "                   extrapolate=True, \n",
    "                   field_type=\"pressure\", \n",
    "                   log_p=False,\n",
    "                   timeidx=0)\n",
    "\n",
    "print (pres_eth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 4.8: xy_to_ll and ll_to_xy\n",
    "\n",
    "In this example, several x,y coordinate values are converted to latitude,longitude values.  \n",
    "\n",
    "These latitude,longitude values are then converted back to x,y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, xy_to_ll, ll_to_xy \n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "lat_lon = xy_to_ll(wrf_file, [20, 30], [50,75])\n",
    "\n",
    "print(\"lat,lon values\")\n",
    "print(lat_lon)\n",
    "print(\"\\n\")\n",
    "\n",
    "x_y = ll_to_xy(wrf_file, lat_lon[0,:], lat_lon[1,:])\n",
    "\n",
    "print(\"x,y values\")\n",
    "print(x_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5.0 Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5.1: Single Wind Barb Example with pyplot\n",
    "\n",
    "In this example, a single wind barb is created in the center of the domain (by masking all other values).\n",
    "\n",
    "This simple example uses only the matplotlib.pyplot API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "# Make a 5x5 grid of missing u,v values\n",
    "u = np.ma.masked_equal(np.zeros((5,5)), 0)\n",
    "v = np.ma.masked_equal(np.zeros((5,5)), 0)\n",
    "\n",
    "# Add u,v winds to center of domain\n",
    "u[2,2] = 10.0\n",
    "v[2,2] = 10.0\n",
    "\n",
    "# Draw a single wind barb in the middle using pyplot API\n",
    "# Note: the axes objects are \"hidden\" in these functions\n",
    "fig = pyplot.figure()\n",
    "pyplot.barbs(u, v)\n",
    "\n",
    "# Set the x and y ranges so the barb is in the middle\n",
    "pyplot.xlim(0, 4)\n",
    "pyplot.ylim(0, 4)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 5.2: Single Wind Barb Using the Axes Object\n",
    "\n",
    "This is the same example as before, but now the Axes objects are used directly, rather than the pure pyplot API.\n",
    "\n",
    "Often you'll use a mix of pyplot and the object API when working with matplotlib, especially when making panel plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "# Make a 5x5 grid of missing u,v values\n",
    "u = np.ma.masked_equal(np.zeros((5,5)), 0)\n",
    "v = np.ma.masked_equal(np.zeros((5,5)), 0)\n",
    "\n",
    "# Add u,v winds to center of domain\n",
    "u[2,2] = 10.0\n",
    "v[2,2] = 10.0\n",
    "\n",
    "# We'll use pyplot to create the figure and \n",
    "# get the axes\n",
    "fig = pyplot.figure()\n",
    "ax = pyplot.axes() # <- Remember this line\n",
    "\n",
    "# Now use the axes directly to create the barbs\n",
    "ax.barbs(u, v)\n",
    "\n",
    "# Set the x and y ranges using the axes directly\n",
    "ax.set_xlim(0, 4)\n",
    "ax.set_ylim(0, 4)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 5.3: Making a Plot of Terrain\n",
    "\n",
    "In this example, terrain is plotted.  Plotting terrain is a good way of checking that your data is mapped correctly.\n",
    "\n",
    "Note:  The first time you run this code, you will need to be connected to the internet so that cartopy can download the map background shapefiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, to_np, get_cartopy, latlon_coords\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get the terrain height\n",
    "terrain = getvar(wrf_file, \"ter\", timeidx=0)\n",
    "\n",
    "# Get the cartopy object and the lat,lon coords\n",
    "cart_proj = get_cartopy(terrain)\n",
    "lats, lons = latlon_coords(terrain)\n",
    "\n",
    "# Create a figure and get the GetAxes object\n",
    "fig = pyplot.figure(figsize=(9, 10))\n",
    "geo_axes = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states.\n",
    "# See the cartopy documentation for more on this.\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "geo_axes.add_feature(states, linewidth=2.0, edgecolor='white', zorder=2)\n",
    "\n",
    "# Set the contour levels\n",
    "levels = np.arange(250., 4000., 500.)\n",
    "\n",
    "# Make the contour lines and fill them.\n",
    "pyplot.contour(to_np(lons), to_np(lats), \n",
    "               to_np(terrain), levels=levels, \n",
    "               colors=\"black\",\n",
    "               transform=crs.PlateCarree())\n",
    "pyplot.contourf(to_np(lons), to_np(lats), \n",
    "                to_np(terrain), levels=levels,\n",
    "                transform=crs.PlateCarree(),\n",
    "                cmap=get_cmap(\"terrain\"))\n",
    "             \n",
    "# Add a color bar. The shrink often needs to be set \n",
    "# by trial and error.\n",
    "pyplot.colorbar(ax=geo_axes, shrink=1.0)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 5.4: Full Plot of Precipitable Water (inches)\n",
    "\n",
    "In this example, precipitable water is plotted for the full domain.\n",
    "\n",
    "The following examples show how you can crop this figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, to_np, get_cartopy, latlon_coords\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get precipitable water in kg/m2 [or mm]\n",
    "pw = getvar(wrf_file, \"pw\", 0)\n",
    "\n",
    "# Get the Precipitable Water in inches \n",
    "# [Note: 1 kg/m2 = 1 mm = .0393701 in]\n",
    "pw_in = pw * .0393701\n",
    "\n",
    "# After a math operation, xarray drops the attributes, so \n",
    "# let's add them back and set the units to be inches\n",
    "pw_in.attrs.update(pw.attrs)\n",
    "pw_in.attrs[\"units\"] = \"in\"\n",
    "\n",
    "\n",
    "# Get the cartopy object and the lat,lon coords\n",
    "cart_proj = get_cartopy(pw_in)\n",
    "lats, lons = latlon_coords(pw_in)\n",
    "\n",
    "# Create a figure and get the GetAxes object\n",
    "fig = pyplot.figure(figsize=(9, 10))\n",
    "geo_axes = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states\n",
    "# See the cartopy documentation for more on this\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "geo_axes.add_feature(states, linewidth=2.0, edgecolor='black', zorder=2)\n",
    "\n",
    "# Set the contour levels so that all plots match\n",
    "levels = np.arange(0, 1.4, .2)\n",
    "\n",
    "# Make the contour lines and fill them.\n",
    "pyplot.contour(to_np(lons), to_np(lats), \n",
    "               to_np(pw_in), levels=levels, colors=\"black\",\n",
    "               transform=crs.PlateCarree())\n",
    "pyplot.contourf(to_np(lons), to_np(lats), \n",
    "                to_np(pw_in), levels=levels, \n",
    "                transform=crs.PlateCarree(),\n",
    "                cmap=get_cmap(\"jet\"))\n",
    "             \n",
    "# Add a color bar. The shrink often needs to be set \n",
    "# by trial and error.\n",
    "pyplot.colorbar(ax=geo_axes, shrink=1.0)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 5.5: Cropping by Slicing the Data\n",
    "\n",
    "In this example, the data is cropped to the lower right quadrant by slicing the data before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, to_np, get_cartopy, latlon_coords\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get precipitable water in kg/m2 [or mm]\n",
    "pw = getvar(wrf_file, \"pw\")\n",
    "\n",
    "# Get the Precipitable Water in inches \n",
    "# [Note: 1 kg/m2 = 1 mm = .0393701 in]\n",
    "pw_in = pw * .0393701\n",
    "\n",
    "# After a math operation, xarray drops the attributes, so \n",
    "# let's add them back and set the units to be inches\n",
    "pw_in.attrs.update(pw.attrs)\n",
    "pw_in.attrs[\"units\"] = \"in\"\n",
    "\n",
    "# Determine the center of the domain in grid coordinates\n",
    "pw_shape = pw_in.shape\n",
    "center_y = int(pw_shape[-2]/2.) - 1\n",
    "center_x = int(pw_shape[-1]/2.) - 1\n",
    "\n",
    "# Slice from bottom to middle for y\n",
    "# Slice from middle to right for x\n",
    "pw_quad = pw_in[..., 0:center_y+1, center_x:]\n",
    "\n",
    "# Get the cartopy object and the lat,lon coords\n",
    "cart_proj = get_cartopy(pw_quad)\n",
    "lats, lons = latlon_coords(pw_quad)\n",
    "\n",
    "# Create a figure and get the GetAxes object\n",
    "fig = pyplot.figure(figsize=(9, 10))\n",
    "geo_axes = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states\n",
    "# See the cartopy documentation for more on this.\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "geo_axes.add_feature(states, linewidth=2.0, edgecolor='black', zorder=2)\n",
    "\n",
    "# Set the contour levels\n",
    "levels = np.arange(0, 1.4, .2)\n",
    "\n",
    "# Make the contour lines and fill them.\n",
    "pyplot.contour(to_np(lons), to_np(lats), \n",
    "               to_np(pw_quad), levels=levels, colors=\"black\",\n",
    "               transform=crs.PlateCarree())\n",
    "pyplot.contourf(to_np(lons), to_np(lats), \n",
    "                to_np(pw_quad), levels=levels, \n",
    "                transform=crs.PlateCarree(),\n",
    "                cmap=get_cmap(\"jet\"))\n",
    "             \n",
    "# Add a color bar. The shrink often needs to be set \n",
    "# by trial and error.\n",
    "pyplot.colorbar(ax=geo_axes, shrink=1.0)\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 5.6: Cropping by Setting the X,Y Extents\n",
    "\n",
    "In this example, the plot is cropped to the lower right quardrant by setting x and y axis extents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, to_np, get_cartopy, latlon_coords\n",
    "from wrf import xy_to_ll, cartopy_xlim, cartopy_ylim\n",
    "from wrf import CoordPair, GeoBounds\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get precipitable water in kg/m2 [or mm]\n",
    "pw = getvar(wrf_file, \"pw\")\n",
    "\n",
    "# Get the Precipitable Water in inches \n",
    "# [Note: 1 kg/m2 = 1 mm = .0393701 in]\n",
    "pw_in = pw * .0393701\n",
    "\n",
    "# After a math operation, xarray drops the attributes, so \n",
    "# let's add them back and set the units to be inches\n",
    "pw_in.attrs.update(pw.attrs)\n",
    "pw_in.attrs[\"units\"] = \"in\"\n",
    "\n",
    "# Get the cartopy object and the lat,lon coords\n",
    "cart_proj = get_cartopy(pw_in)\n",
    "lats, lons = latlon_coords(pw_in)\n",
    "\n",
    "# Create a figure and get the GetAxes object\n",
    "fig = pyplot.figure(figsize=(9, 10))\n",
    "geo_axes = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states\n",
    "# See the cartopy documentation for more on this\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "geo_axes.add_feature(states, linewidth=2.0, edgecolor='black', zorder=2)\n",
    "\n",
    "# Set the contour levels\n",
    "levels = np.arange(0, 1.4, .2)\n",
    "\n",
    "# Make the contour lines and fill them.\n",
    "pyplot.contour(to_np(lons), to_np(lats), \n",
    "               to_np(pw_in), levels=levels, colors=\"black\",\n",
    "               transform=crs.PlateCarree())\n",
    "pyplot.contourf(to_np(lons), to_np(lats), \n",
    "                to_np(pw_in), levels=levels, \n",
    "                transform=crs.PlateCarree(),\n",
    "                cmap=get_cmap(\"jet\"))\n",
    "             \n",
    "# Add a color bar. The shrink often needs to be set \n",
    "# by trial and error.\n",
    "pyplot.colorbar(ax=geo_axes, shrink=1.0)\n",
    "\n",
    "# Set up the x, y extents\n",
    "\n",
    "# Determine the center of the domain in grid coordinates\n",
    "pw_shape = pw_in.shape\n",
    "start_y = 0\n",
    "center_y = int(pw_shape[-2]/2.) - 1\n",
    "center_x = int(pw_shape[-1]/2.) - 1\n",
    "end_x = int(pw_shape[-1]) - 1\n",
    "\n",
    "# Get the lats and lons for the start, center, and end points\n",
    "# (Normally you would just set these yourself)\n",
    "center_latlon = xy_to_ll(wrf_file, \n",
    "                         [center_x, end_x], \n",
    "                         [start_y, center_y])\n",
    "\n",
    "start_lat = center_latlon[0,0]\n",
    "end_lat = center_latlon[0,1]\n",
    "start_lon = center_latlon[1,0]\n",
    "end_lon = center_latlon[1,1]\n",
    "\n",
    "# Set the extents\n",
    "geo_bounds = GeoBounds(CoordPair(lat=start_lat, lon=start_lon),\n",
    "                       CoordPair(lat=end_lat, lon=end_lon))\n",
    "geo_axes.set_xlim(cartopy_xlim(pw_in, geobounds=geo_bounds))\n",
    "geo_axes.set_ylim(cartopy_ylim(pw_in, geobounds=geo_bounds))\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 OpenMP and Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples below gradually improve upon performance by using OpenMP, adjusting the scheduler, and using a variable cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6.1: Performance Improvement with OpenMP\n",
    "\n",
    "In this example, all diagnostics are calculated using one thread, and then using the maximum number of threads available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, ALL_TIMES, omp_enabled, \n",
    "                 omp_get_num_procs, omp_set_num_threads)\n",
    "\n",
    "if not omp_enabled():\n",
    "    raise RuntimeError(\"OpenMP is not available in this build\")\n",
    "\n",
    "# For this demo, only use the first file since there are 24 time steps\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "    \n",
    "vars = (\"avo\", \"eth\", \"cape_2d\", \"cape_3d\", \"ctt\", \"dbz\", \"mdbz\",\n",
    "        \"geopt\", \"helicity\", \"lat\", \"lon\", \"omg\", \"p\", \"pressure\",\n",
    "        \"pvo\", \"pw\", \"rh2\", \"rh\", \"slp\", \"ter\", \"td2\", \"td\", \"tc\",\n",
    "        \"theta\", \"tk\", \"tv\", \"twb\", \"updraft_helicity\", \"ua\", \"va\",\n",
    "        \"wa\", \"uvmet10\", \"uvmet\", \"z\", \"cfrac\")    \n",
    "\n",
    "print(\"Running with a single CPU\")\n",
    "\n",
    "# Use 1 CPU\n",
    "omp_set_num_threads(1)\n",
    "\n",
    "start = time()\n",
    "\n",
    "for var in vars:\n",
    "    v = getvar(wrf_file, var, 0)\n",
    "    \n",
    "end = time()\n",
    "\n",
    "print(\"Time taken: {} s\".format(end-start))\n",
    "\n",
    "print (\"Running with {} CPUs\".format(omp_get_num_procs()))\n",
    "\n",
    "# Use Max CPUs\n",
    "omp_set_num_threads(omp_get_num_procs())\n",
    "\n",
    "start = time()\n",
    "\n",
    "for var in vars:\n",
    "    v = getvar(wrf_file, var, 0)\n",
    "    \n",
    "end = time()\n",
    "\n",
    "print(\"Time taken: {} s\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenMP Scheduling Types\n",
    "\n",
    "WRF-Python uses *runtime* scheduling, which means that one of the scheduler types defined below must be set at runtime rather than compile time.\n",
    "\n",
    "- **wrf.OMP_SCHED_STATIC**: Divide the loop in to equal-sized chunks (default chunk_size = loop_count/num_threads) \n",
    "  **[wrf-python default]**\n",
    "- **wrf.OMP_SCHED_DYNAMIC**: Use internal loop queue to give a chunk-sized block of loop iterations to each thread. \n",
    "  When thread is finished, it retrieves next block to work on (default chunk_size = 1).\n",
    "- **wrf.OMP_SCHED_GUIDED**: Similar to OMP_SCHED_DYNAMIC, but the chunk size starts off large and decreases to better \n",
    "  handle load imbalance between iterations. (default chunk_size = loop_count/num_threads)\n",
    "- **wrf.OMP_SCHED_AUTO**: The decision regarding scheduling is delegated to the OpenMP implementation for the compiler\n",
    "  (magic!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6.2: OpenMP Scheduling Types\n",
    "\n",
    "In this example, the various scheduler types are compared to see if performance is improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, ALL_TIMES, omp_enabled, \n",
    "                 omp_get_num_procs, omp_set_num_threads,\n",
    "                 omp_set_schedule, OMP_SCHED_STATIC,\n",
    "                 OMP_SCHED_DYNAMIC, \n",
    "                 OMP_SCHED_GUIDED, OMP_SCHED_AUTO)\n",
    "\n",
    "if not omp_enabled():\n",
    "    raise RuntimeError(\"OpenMP is not available in this build\")\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "    \n",
    "vars = (\"avo\", \"eth\", \"cape_2d\", \"cape_3d\", \"ctt\", \"dbz\", \"mdbz\",\n",
    "        \"geopt\", \"helicity\", \"lat\", \"lon\", \"omg\", \"p\", \"pressure\",\n",
    "        \"pvo\", \"pw\", \"rh2\", \"rh\", \"slp\", \"ter\", \"td2\", \"td\", \"tc\",\n",
    "        \"theta\", \"tk\", \"tv\", \"twb\", \"updraft_helicity\", \"ua\", \"va\",\n",
    "        \"wa\", \"uvmet10\", \"uvmet\", \"z\", \"cfrac\")    \n",
    "\n",
    "omp_set_num_threads(omp_get_num_procs())\n",
    "\n",
    "chunk_size = 0\n",
    "\n",
    "sched_string_map = {int(OMP_SCHED_STATIC) : \"OMP_SCHED_STATIC\", \n",
    "                    int(OMP_SCHED_DYNAMIC) : \"OMP_SCHED_DYNAMIC\",  \n",
    "                    int(OMP_SCHED_GUIDED) : \"OMP_SCHED_GUIDED\",\n",
    "                    int(OMP_SCHED_AUTO) : \"OMP_SCHED_AUTO\"}\n",
    "\n",
    "for sched in (OMP_SCHED_STATIC, OMP_SCHED_DYNAMIC, \n",
    "              OMP_SCHED_GUIDED, OMP_SCHED_AUTO):\n",
    "    omp_set_schedule(sched, chunk_size)\n",
    "    sched_string = sched_string_map[int(sched)]\n",
    "    print(\"Running with sheduler: {}\".format(sched_string))\n",
    "    \n",
    "    start = time()\n",
    "    for var in vars:\n",
    "        v = getvar(wrf_file, var, 0)\n",
    "    end = time()\n",
    "    \n",
    "    print(\"Time taken using scheduler {}: {} s\".format(sched_string, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRF-Python and Variable Extraction\n",
    "\n",
    "- Everytime you call wrf.getvar, the variables needed for the calculation are extracted from the NetCDF file.\n",
    "- The same variables are going to be extracted over and over and over and over and...\n",
    "- To prevent this, you can use the *cache* argument to getvar.\n",
    "\n",
    "## The *cache* Argument to getvar\n",
    "\n",
    "- Normally used internally so that variables containing metadata aren't extracted more than once.\n",
    "- Can also be used to prevent the repeated extraction of common variables.\n",
    "- Should be a dictionary of variable name to variable data.\n",
    "- Good variables to use: **P, PB, PH, PHB, T, QVAPOR, HGT, PSFC, U, V, W**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6.3: Using the cache Argument\n",
    "\n",
    "In this example, a variable cache is used to show how much performance can be improved by removing the variable extraction cost. The scheduler types are compared as in the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, extract_vars, ALL_TIMES, omp_enabled, \n",
    "                 omp_get_num_procs, omp_set_num_threads,\n",
    "                 omp_set_schedule, OMP_SCHED_STATIC,\n",
    "                 OMP_SCHED_DYNAMIC, \n",
    "                 OMP_SCHED_GUIDED, OMP_SCHED_AUTO)\n",
    "\n",
    "if not omp_enabled():\n",
    "    raise RuntimeError(\"OpenMP is not available in this build\")\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "print(\"Caching common variables\")\n",
    "cache = extract_vars(wrf_file, 0, \n",
    "                     (\"P\", \"PSFC\", \"PB\", \"PH\", \"PHB\",\n",
    "                      \"T\", \"QVAPOR\", \"HGT\", \"U\", \"V\",\n",
    "                      \"W\"))\n",
    "print(\"Finished caching\")\n",
    "print(\"----------------\")\n",
    "    \n",
    "vars = (\"avo\", \"eth\", \"cape_2d\", \"cape_3d\", \"ctt\", \"dbz\", \"mdbz\",\n",
    "        \"geopt\", \"helicity\", \"lat\", \"lon\", \"omg\", \"p\", \"pressure\",\n",
    "        \"pvo\", \"pw\", \"rh2\", \"rh\", \"slp\", \"ter\", \"td2\", \"td\", \"tc\",\n",
    "        \"theta\", \"tk\", \"tv\", \"twb\", \"updraft_helicity\", \"ua\", \"va\",\n",
    "        \"wa\", \"uvmet10\", \"uvmet\", \"z\", \"cfrac\")    \n",
    "\n",
    "omp_set_num_threads(omp_get_num_procs())\n",
    "\n",
    "chunk_size = 0\n",
    "\n",
    "sched_string_map = {int(OMP_SCHED_STATIC) : \"OMP_SCHED_STATIC\", \n",
    "                    int(OMP_SCHED_DYNAMIC) : \"OMP_SCHED_DYNAMIC\",  \n",
    "                    int(OMP_SCHED_GUIDED) : \"OMP_SCHED_GUIDED\",\n",
    "                    int(OMP_SCHED_AUTO) : \"OMP_SCHED_AUTO\"}\n",
    "\n",
    "for sched in (OMP_SCHED_STATIC, OMP_SCHED_DYNAMIC, \n",
    "              OMP_SCHED_GUIDED, OMP_SCHED_AUTO):\n",
    "    omp_set_schedule(sched, chunk_size)\n",
    "    sched_string = sched_string_map[int(sched)]\n",
    "    print(\"Running with sheduler: {}\".format(sched_string))\n",
    "    \n",
    "    start = time()\n",
    "    for var in vars:\n",
    "        v = getvar(wrf_file, var, 0, cache=cache)\n",
    "    end = time()\n",
    "    \n",
    "    print(\"Time taken using scheduler {}: {} s\".format(sched_string, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 7.0 Advanced Examples\n",
    "\n",
    "These examples are a lot more complicated than the previous examples, but you might find them more useful in the real world.  \n",
    "\n",
    "We might not have time to cover these in the tutorial, so hang on to them for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example 7.1: Overlaying Multiple Diagnostics\n",
    "\n",
    "In this example, we're going to add winds and dewpoint to sea level pressure.  \n",
    "\n",
    "[Note: not the prettiest picture for the mountains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, to_np, get_cartopy, latlon_coords, cartopy_xlim, cartopy_ylim\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Get the slp, td2, u, and v variables\n",
    "slp = getvar(wrf_file, \"slp\", timeidx=0)\n",
    "td2 = getvar(wrf_file, \"td2\", timeidx=0, units=\"degF\")\n",
    "u_sfc = getvar(wrf_file, \"ua\", timeidx=0, units=\"kt\")[0,:]\n",
    "v_sfc = getvar(wrf_file, \"va\", timeidx=0, units=\"kt\")[0,:]\n",
    "\n",
    "# Get the cartopy object and the lat,lon coords\n",
    "cart_proj = get_cartopy(slp)\n",
    "lats, lons = latlon_coords(slp)\n",
    "\n",
    "# Create a figure and get the GetAxes object\n",
    "fig = pyplot.figure(figsize=(9, 10))\n",
    "geo_axes = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states and coastlines\n",
    "# See the cartopy documentation for more on this.\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "geo_axes.add_feature(states, linewidth=2.0, edgecolor='black', zorder=2)\n",
    "\n",
    "\n",
    "# Manually setting the contour levels\n",
    "slp_levels = np.arange(980.,1030.,6.0)\n",
    "td2_levels = np.arange(10., 79., 3.)\n",
    "\n",
    "\n",
    "# Manually setting the td2 RGB colors (normalized to 1)\n",
    "# These colors originated from the now defunct hoot.metr.ou.edu\n",
    "# They work well for detecting moisture boundaries (e.g. the dryline)\n",
    "td2_rgb = np.array([[181,82,0], [181,82,0],\n",
    "                  [198,107,8], [206,107,8],\n",
    "                  [231,140,8], [239,156,8],\n",
    "                  [247,173,24], [255,189,41],\n",
    "                  [255,212,49], [255,222,66],\n",
    "                  [255,239,90], [247,255,123],\n",
    "                  [214,255,132], [181,231,148],\n",
    "                  [156,222,156], [132,222,132],\n",
    "                  [112,222,112], [82,222,82],\n",
    "                  [57,222,57], [33,222,33],\n",
    "                  [8,206,8], [0,165,0],\n",
    "                  [0,140,0], [3,105,3]]) / 255.0\n",
    "    \n",
    "td2_cmap, td2_norm = from_levels_and_colors(td2_levels, td2_rgb, extend=\"both\")\n",
    "\n",
    "# Make the pressure contour lines\n",
    "slp_contours = pyplot.contour(to_np(lons), \n",
    "                              to_np(lats), \n",
    "                              to_np(slp), \n",
    "                              levels=slp_levels, \n",
    "                              colors=\"black\",\n",
    "                              transform=crs.PlateCarree())\n",
    "\n",
    "# Make filled contours of dewpoint\n",
    "pyplot.contourf(to_np(lons), \n",
    "                to_np(lats), \n",
    "                to_np(td2), \n",
    "                levels=td2_levels, \n",
    "                cmap=td2_cmap, \n",
    "                norm=td2_norm,\n",
    "                extend=\"both\",\n",
    "                transform=crs.PlateCarree())\n",
    "\n",
    "# Plot the wind barbs, but only plot ~10 barbs in each direction.\n",
    "thin = [int(x/10.) for x in lons.shape]\n",
    "pyplot.barbs(to_np(lons[::thin[0], ::thin[1]]), \n",
    "             to_np(lats[::thin[0], ::thin[1]]), \n",
    "             to_np(u_sfc[::thin[0], ::thin[1]]), \n",
    "             to_np(v_sfc[::thin[0], ::thin[1]]),\n",
    "             transform=crs.PlateCarree())\n",
    "\n",
    "# Add contour labels for pressure\n",
    "pyplot.clabel(slp_contours, fmt=\"%i\")\n",
    "\n",
    "# Add a color bar. The shrink often needs to be set \n",
    "# by trial and error.\n",
    "pyplot.colorbar(ax=geo_axes, shrink=1.0, extend=\"both\")\n",
    "\n",
    "# Set the map bounds\n",
    "pyplot.xlim(cartopy_xlim(slp))\n",
    "pyplot.ylim(cartopy_ylim(slp))\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7.2: 500 hPa RH and Winds with interplevel\n",
    "\n",
    "In this example, the 500 hPa relative humidity is plotted with wind barbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, to_np, get_cartopy, latlon_coords, interplevel,\n",
    "                 cartopy_xlim, cartopy_ylim)\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "# Extract the pressure, relative humidity, and wind variables\n",
    "p = getvar(wrf_file, \"pressure\")\n",
    "rh = getvar(wrf_file, \"rh\")\n",
    "ua = getvar(wrf_file, \"ua\", units=\"kt\")\n",
    "va = getvar(wrf_file, \"va\", units=\"kt\")\n",
    "\n",
    "# Interpolate rh, u, and v winds at the level specified below\n",
    "level = 500.\n",
    "rh_level = interplevel(rh, p, level)\n",
    "u_level = interplevel(ua, p, level)\n",
    "v_level = interplevel(va, p, level)\n",
    "\n",
    "# Get the lat/lon coordinates\n",
    "lats, lons = latlon_coords(rh_level)\n",
    "\n",
    "# Get the map projection information\n",
    "cart_proj = get_cartopy(rh_level)\n",
    "\n",
    "# Create the figure\n",
    "fig = pyplot.figure(figsize=(9,10))\n",
    "ax = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and add the states and coastlines\n",
    "states = NaturalEarthFeature(category='cultural', \n",
    "                             scale='50m', \n",
    "                             facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "ax.add_feature(states, linewidth=2.0, edgecolor='black', zorder=2)\n",
    "\n",
    "# Add the RH contour lines\n",
    "levels = np.arange(0, 110, 10)\n",
    "contours = pyplot.contourf(to_np(lons), \n",
    "                           to_np(lats), \n",
    "                           to_np(rh_level), \n",
    "                           levels=levels, \n",
    "                           cmap=get_cmap(\"PRGn\"),\n",
    "                           transform=crs.PlateCarree())\n",
    "\n",
    "pyplot.colorbar(contours, ax=ax, shrink=1.0)\n",
    "\n",
    "# Add the wind barbs, only plotting 10 barbs in each direction\n",
    "# Also, skip the border barbs\n",
    "thin = [int(x/10.) for x in lons.shape]\n",
    "pyplot.barbs(to_np(lons[::thin[0], ::thin[1]]), \n",
    "             to_np(lats[::thin[0], ::thin[1]]), \n",
    "             to_np(u_level[::thin[0], ::thin[1]]),\n",
    "             to_np(v_level[::thin[0], ::thin[1]]), \n",
    "             length=6,\n",
    "             transform=crs.PlateCarree())\n",
    "\n",
    "# Set the map bounds\n",
    "ax.set_xlim(cartopy_xlim(rh_level))\n",
    "ax.set_ylim(cartopy_ylim(rh_level))\n",
    "\n",
    "ax.gridlines()\n",
    "\n",
    "pyplot.title(\"{} MB RH (%) and Barbs (kt)\".format(int(level)))\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7.3: Precipitation Accumulation\n",
    "\n",
    "In this example, the precipitation accumulation for one day is plotted every 4 hours. \n",
    "\n",
    "The WRF files used for this tutorial use precipitation buckets, which is common for long running simulations, but not usually used for short term simulations. At this time, WRF-Python does not provide a 'getvar' routine for computing this, so we have to do it manually.\n",
    "\n",
    "To compute precipitation, you need to add the precipitation from the cumulus and microphysics schemes to get the \n",
    "total precipitation. Precipitation is accumulated from the start of the WRF simulation. In this data set, every time 100 mm is accumulated, an integer is incremented for the accumulation variables. So, to get the total precipitation, you do:\n",
    "\n",
    "    TotalAccumPrecip = (I_RAINC * bucket_mm) + RAINC + (I_RAINNC * bucket_mm) + RAINNC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import from_levels_and_colors, LinearSegmentedColormap\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature, COLORS\n",
    "from netCDF4 import Dataset\n",
    "from xarray import DataArray\n",
    "from wrf import (getvar, extract_global_attrs, ALL_TIMES, to_np, get_cartopy, latlon_coords, vertcross,\n",
    "                 cartopy_xlim, cartopy_ylim, interpline)\n",
    "\n",
    "\n",
    "file_paths = multiple_wrf_files()\n",
    "wrf_files = [Dataset(file_path) for file_path in file_paths]\n",
    "\n",
    "# Get the WRF precipitation variables\n",
    "rainc = getvar(wrf_files, \"RAINC\", ALL_TIMES)\n",
    "rainnc = getvar(wrf_files, \"RAINNC\", ALL_TIMES)\n",
    "i_rainc = getvar(wrf_files, \"I_RAINC\", ALL_TIMES)\n",
    "i_rainnc = getvar(wrf_files, \"I_RAINNC\", ALL_TIMES)\n",
    "bucket_mm = extract_global_attrs(wrf_files, (\"BUCKET_MM\",))[\"BUCKET_MM\"]\n",
    "\n",
    "# This is \"RAINC + RAINNC\" using precip buckets\n",
    "total_accum = (i_rainc * bucket_mm + rainc) + (i_rainnc * bucket_mm + rainnc)\n",
    "\n",
    "# Get the precipitation accumulations in 4 hour periods\n",
    "# This numpy notation is the same as:\n",
    "#     four_hour_accums[0,:] = total_accum[4, :] - total_accum[0,:]\n",
    "#     four_hour_accums[1,:] = total_accum[8, :] - total_accum[0,:]\n",
    "#     four_hour_accums[2,:] = total_accum[12, :] - total_accum[0,:]\n",
    "#     ...\n",
    "four_hour_accums = total_accum[4:25:4,:] - total_accum[0,:]\n",
    "\n",
    "# Convert the precipitation from mm to inches\n",
    "four_hour_accums = four_hour_accums * 0.0393701\n",
    "\n",
    "# Let's set the metadata for this variable\n",
    "four_hour_accums.name = \"PRECIP_4HR\"\n",
    "four_hour_accums.attrs.update(rainc.attrs)\n",
    "four_hour_accums.attrs[\"description\"] = \"precip accumulation 4 hour intervals\"\n",
    "four_hour_accums.attrs[\"units\"] = \"in\"\n",
    "# Let's make a new secondary coordinate for the time interval labels\n",
    "four_hour_accums.coords[\"accum_hrs\"] = (\"Time\", [4, 8, 12, 16, 20, 24])\n",
    "\n",
    "# Get the lat/lon points\n",
    "lats, lons = latlon_coords(four_hour_accums)\n",
    "\n",
    "# Get the cartopy projection object\n",
    "cart_proj = get_cartopy(four_hour_accums)\n",
    "\n",
    "# Create the figure\n",
    "fig = pyplot.figure(figsize=(16,20))\n",
    "\n",
    "# Download and create the states, land, and oceans using cartopy features\n",
    "states = NaturalEarthFeature(category='cultural', scale='50m', facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "land = NaturalEarthFeature(category='physical', name='land', scale='50m',\n",
    "                           facecolor=COLORS['land'])\n",
    "\n",
    "# Making precipitation levels using several groupings of evenly spaced levels\n",
    "# (Taken from www.twisterdata.com).\n",
    "precip_levels = np.append(np.arange(.01, .05, .02), np.arange(.05, .30, .05))\n",
    "precip_levels = np.append(precip_levels, np.arange(.30, 1.0, .1))\n",
    "precip_levels = np.append(precip_levels, np.arange(1.0, 2.0, .25))\n",
    "precip_levels = np.append(precip_levels, np.arange(2.0, 5.0, .5))\n",
    "\n",
    "# Here is how you can truncate an existing colormap in to a subset of it.\n",
    "orig_cmap = get_cmap(\"gist_ncar\")\n",
    "cmap = LinearSegmentedColormap.from_list(\"gist_ncar_trunc\", \n",
    "                                         orig_cmap(np.linspace(.12, .9, 256)))\n",
    "\n",
    "# Make the 6 subplots\n",
    "for plotid in range(6):\n",
    "    \n",
    "    # The figure that will have 6 subplots (3 rows, 2 columns)\n",
    "    # Note: subplot indexes start at 1 instead of 0\n",
    "    ax = fig.add_subplot(3,2,plotid+1, projection=cart_proj)\n",
    "\n",
    "    accum = four_hour_accums[plotid,:]\n",
    "    accum_hr = int(accum[\"accum_hrs\"])\n",
    "    \n",
    "    # Make the precip accum contours\n",
    "    precip_contours = ax.contourf(to_np(lons), \n",
    "                                  to_np(lats), \n",
    "                                  to_np(accum), \n",
    "                                  levels=precip_levels,  \n",
    "                                  cmap=cmap,\n",
    "                                  zorder=2,\n",
    "                                  transform=crs.PlateCarree())\n",
    "\n",
    "\n",
    "    # Draw the oceans, land, and states\n",
    "    ax.add_feature(states, linewidth=2.0, edgecolor=\"white\", zorder=3)\n",
    "    ax.add_feature(land, zorder=1)\n",
    "    \n",
    "    cb_precip = fig.colorbar(precip_contours, ax=ax)\n",
    "    \n",
    "    ax.set_xlim(cartopy_xlim(accum))\n",
    "    ax.set_ylim(cartopy_ylim(accum))\n",
    "\n",
    "    # Add a title\n",
    "    ax.set_title(\"Precip Accum (in) After {} Hours\".format(accum_hr), {\"fontsize\" : 12})\n",
    "\n",
    "pyplot.tight_layout()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7.4: Cross Section Panel Plot\n",
    "\n",
    "In this example, a panel plot is created with one plot showing maximum refleictivity with the horizontal cross section line, and the second plot is a vertical cross section for radar reflectivity with the terrain heights added to show the mountains.\n",
    "\n",
    "First, in the cell below, define your cross section in latitude,longitude coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrf import CoordPair\n",
    "\n",
    "cross_start = CoordPair(lat=43.5, lon=-116.5)\n",
    "cross_end = CoordPair(lat=43.5, lon=-114)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you modified the cell above, the original values were:\n",
    "\n",
    "``` python\n",
    "cross_start = CoordPair(lat=43.5, lon=-116.5)\n",
    "cross_end = CoordPair(lat=43.5, lon=-114.0)\n",
    "```\n",
    "\n",
    "Now run the cell below to generate a cross section plot of reflectivity.\n",
    "\n",
    "(Also remember to run the cell below again if you make changes to the cross section start and end points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature, COLORS\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, to_np, get_cartopy, latlon_coords, vertcross,\n",
    "                 cartopy_xlim, cartopy_ylim, interpline)\n",
    "\n",
    "try:\n",
    "    cross_start\n",
    "    cross_end\n",
    "except NameError:\n",
    "    raise RuntimeError(\"you didn't run the previous cell\")\n",
    "\n",
    "file_path = multiple_wrf_files()\n",
    "wrf_file = [Dataset(x) for x in file_path]\n",
    "\n",
    "# Get the WRF variables\n",
    "ht = getvar(wrf_file, \"z\", timeidx=-1)\n",
    "ter = getvar(wrf_file, \"ter\", timeidx=-1)\n",
    "dbz = getvar(wrf_file, \"dbz\", timeidx=-1)\n",
    "max_dbz = getvar(wrf_file, \"mdbz\", timeidx=-1)\n",
    "Z = 10**(dbz/10.) # Use linear Z for interpolation\n",
    "\n",
    "# Compute the vertical cross-section interpolation.  Also, include the lat/lon\n",
    "# points along the cross-section in the metadata by setting latlon to True.\n",
    "z_cross = vertcross(Z, ht, wrfin=wrf_file, \n",
    "                    start_point=cross_start, \n",
    "                    end_point=cross_end,\n",
    "                    latlon=True, meta=True)\n",
    "\n",
    "# Convert back to dBz after interpolation\n",
    "dbz_cross = 10.0 * np.log10(z_cross)\n",
    "\n",
    "# Add back the attributes that xarray dropped from the operations above\n",
    "dbz_cross.attrs.update(z_cross.attrs)\n",
    "dbz_cross.attrs[\"description\"] = \"radar reflectivity cross section\"\n",
    "dbz_cross.attrs[\"units\"] = \"dBZ\"\n",
    "\n",
    "# To remove the slight gap between the dbz and terrain due to contouring, the new vertical \n",
    "# grid spacing, and grid staggering, let's fill in the lower grid cells with the first non-missing \n",
    "# value for each column.\n",
    "\n",
    "# Make a copy of the z cross data. Let's use regular numpy arrays for this.\n",
    "dbz_cross_filled = np.ma.copy(to_np(dbz_cross))\n",
    "\n",
    "# For each cross section column, find the first index with non-missing values and copy\n",
    "# these to the missing elements below.\n",
    "for i in range(dbz_cross_filled.shape[-1]):\n",
    "    column_vals = dbz_cross_filled[:,i]\n",
    "    # Let's find all values that aren't filled. The nonzero function checks for nonzero \n",
    "    # values, but 0s are ok for reflectivity, so let's just get all values greater \n",
    "    # than some nonsensical negative and use nonzero() on the boolean array. \n",
    "    first_idx = int(np.transpose((column_vals > -200.).nonzero())[0])\n",
    "    dbz_cross_filled[0:first_idx, i] = dbz_cross_filled[first_idx, i]\n",
    "            \n",
    "# Get the terrain heights along the cross section line\n",
    "ter_line = interpline(ter, wrfin=wrf_file, start_point=cross_start, end_point=cross_end)\n",
    "\n",
    "# Get the lat/lon points\n",
    "lats, lons = latlon_coords(dbz)\n",
    "\n",
    "# Get the cartopy projection object\n",
    "cart_proj = get_cartopy(dbz)\n",
    "\n",
    "# Create a figure that will have 2 subplots (1 row, 2 columns)\n",
    "fig = pyplot.figure(figsize=(14,7))\n",
    "ax_dbz = fig.add_subplot(1,2,1,projection=cart_proj)\n",
    "ax_cross = fig.add_subplot(1,2,2)\n",
    "\n",
    "# Download and create the states and land\n",
    "states = NaturalEarthFeature(category='cultural', scale='50m', facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "land = NaturalEarthFeature(category='physical', name='land', scale='50m',\n",
    "                           facecolor=COLORS['land'])\n",
    "\n",
    "dbz_levels = np.arange(5., 80., 5.)\n",
    "\n",
    "# This is the NWS color table.\n",
    "dbz_rgb = np.array([[4,233,231],\n",
    "                    [1,159,244], [3,0,244],\n",
    "                    [2,253,2], [1,197,1],\n",
    "                    [0,142,0], [253,248,2],\n",
    "                    [229,188,0], [253,149,0],\n",
    "                    [253,0,0], [212,0,0],\n",
    "                    [188,0,0],[248,0,253],\n",
    "                    [152,84,198],[253,253,253]], np.float32) / 255.0\n",
    "    \n",
    "dbz_map, dbz_norm = from_levels_and_colors(dbz_levels, dbz_rgb, extend=\"max\")\n",
    "\n",
    "# Make the dbz contours on the map\n",
    "dbz_contours = ax_dbz.contourf(to_np(lons), \n",
    "                    to_np(lats), \n",
    "                    to_np(max_dbz), \n",
    "                    levels=dbz_levels,\n",
    "                    cmap=dbz_map, \n",
    "                    norm=dbz_norm, \n",
    "                    extend=\"max\",\n",
    "                    zorder=3, \n",
    "                    transform=crs.PlateCarree())\n",
    "\n",
    "# Draw the cross section line\n",
    "ax_dbz.plot([cross_start.lon, cross_end.lon], \n",
    "            [cross_start.lat, cross_end.lat],\n",
    "            color=\"black\",\n",
    "            linewidth=3.0,\n",
    "            marker=\"o\",  \n",
    "            zorder=5,\n",
    "            transform=crs.PlateCarree())\n",
    "\n",
    "# Draw the oceans, land, and states\n",
    "ax_dbz.add_feature(states, linewidth=2.0, edgecolor=\"black\", zorder=3)\n",
    "ax_dbz.add_feature(land)\n",
    "\n",
    "# Make the cross section plot for dbz\n",
    "dbz_levels = np.arange(5.,75.,5.)\n",
    "xs = np.arange(0, dbz_cross.shape[-1], 1)\n",
    "ys = to_np(dbz_cross.coords[\"vertical\"])\n",
    "dbz_contours = ax_cross.contourf(xs, \n",
    "                                 ys, \n",
    "                                 to_np(dbz_cross_filled), \n",
    "                                 levels=dbz_levels,\n",
    "                                 cmap=dbz_map, \n",
    "                                 norm=dbz_norm, \n",
    "                                 extend=\"max\")\n",
    "cb_dbz = fig.colorbar(dbz_contours, ax=ax_cross)\n",
    "cb_dbz.ax.tick_params(labelsize=8)\n",
    "\n",
    "# Fill in the mountain area\n",
    "ht_fill = ax_cross.fill_between(xs, 0, to_np(ter_line), facecolor=\"saddlebrown\")\n",
    "\n",
    "# Set the x-ticks to use latitude and longitude labels\n",
    "coord_pairs = to_np(dbz_cross.coords[\"xy_loc\"])\n",
    "x_ticks = np.arange(coord_pairs.shape[0])\n",
    "x_labels = [pair.latlon_str() for pair in to_np(coord_pairs)]\n",
    "\n",
    "# Set the desired number of x ticks below\n",
    "num_ticks = 5\n",
    "thin = int((len(x_ticks) / num_ticks) + .5)\n",
    "ax_cross.set_xticks(x_ticks[::thin])\n",
    "ax_cross.set_xticklabels(x_labels[::thin], rotation=45, fontsize=8)\n",
    "\n",
    "# Set the x-axis and  y-axis labels\n",
    "ax_cross.set_xlabel(\"Latitude, Longitude\", fontsize=12)\n",
    "ax_cross.set_ylabel(\"Height (m)\", fontsize=12)\n",
    "\n",
    "# Add a title\n",
    "ax_dbz.set_title(\"Maximum Reflectivity (dBZ)\", {\"fontsize\" : 14})\n",
    "ax_cross.set_title(\"Cross-Section of Reflectivity (dBZ)\", {\"fontsize\" : 14})\n",
    "\n",
    "pyplot.tight_layout()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7.5: Animations\n",
    "\n",
    "In this example, an animation of radar reflectivity is generated.\n",
    "\n",
    "To make animations, the ffmpeg package can be used to make movies, but for this example we're going to make a Javascript animation.\n",
    "\n",
    "To create an animation, you have to define a function that generates the frames (in this example it is named *animate*).\n",
    "\n",
    "You pass this animation function to the FuncAnimation object.\n",
    "\n",
    "You must also supply some kind of generator that passes the arguments to the animate function, or you can just supply an integer and the FuncAnimation object will use the range() function.  In this case, we're just generating integer values which represents the Time index.\n",
    "\n",
    "To render the animation in a jupyter notebook, we make use of the HTML object from Ipython.display and the *to_jshtml* method for the FuncAnimation object to make the Javascript frame animator. If you have ffmpeg installed, you can use the *to_html5_video* to make a movie.\n",
    "\n",
    "Below the animation will also be a static image of the first frame for radar reflectivity. I haven't figured out how to prevent this, so don't worry about it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot, rc\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from cartopy import crs\n",
    "from cartopy.feature import NaturalEarthFeature, COLORS\n",
    "from netCDF4 import Dataset\n",
    "from wrf import (getvar, to_np, get_cartopy, latlon_coords, vertcross,\n",
    "                 cartopy_xlim, cartopy_ylim, ALL_TIMES, extract_vars,\n",
    "                 omp_set_num_threads, omp_get_num_procs)\n",
    "\n",
    "file_path = single_wrf_file()\n",
    "wrf_file = Dataset(file_path)\n",
    "\n",
    "print(\"Calculating dbz...\")\n",
    "\n",
    "# Get DBZ for all times\n",
    "cache = extract_vars(wrf_file, ALL_TIMES, (\"T\", \"P\", \"PB\", \"QVAPOR\", \n",
    "                                           \"QRAIN\", \"QSNOW\", \"QGRAUP\"))\n",
    "\n",
    "omp_set_num_threads(omp_get_num_procs())\n",
    "\n",
    "dbz_all = getvar(wrf_file, \"mdbz\", timeidx=ALL_TIMES, cache=cache)\n",
    "\n",
    "# Get the cartopy projection object\n",
    "cart_proj = get_cartopy(dbz_all)\n",
    "\n",
    "fig = pyplot.figure(figsize=(8,10))\n",
    "ax = pyplot.axes(projection=cart_proj)\n",
    "\n",
    "# Download and create the states and land\n",
    "states = NaturalEarthFeature(category='cultural', scale='50m', facecolor='none',\n",
    "                             name='admin_1_states_provinces_shp')\n",
    "land = NaturalEarthFeature(category='physical', name='land', scale='50m',\n",
    "                           facecolor=COLORS['land'])\n",
    "\n",
    "dbz_levels = np.arange(5, 80, 5)\n",
    "num_frames = dbz_all.shape[0]\n",
    "\n",
    "# This is the NWS radar color table\n",
    "dbz_rgb = np.array([[4,233,231],\n",
    "                    [1,159,244], [3, 0, 244],\n",
    "                    [2,253,2], [1,197,1],\n",
    "                    [0,142,0], [253,248,2],\n",
    "                    [229,188,0], [253,149,0],\n",
    "                    [253,0,0], [212,0,0],\n",
    "                    [188,0,0],[248,0,253],\n",
    "                    [152,84,198],[253,253,253]], np.float32) / 255.0\n",
    "    \n",
    "dbz_map, dbz_norm = from_levels_and_colors(dbz_levels, dbz_rgb, extend=\"max\")\n",
    "\n",
    "\n",
    "# This init function is used to set up the colorbar, otherwise it gets \n",
    "# repeatedly drawn.\n",
    "def init():\n",
    "    \n",
    "    dbz = dbz_all[0,:]\n",
    "    \n",
    "    lats, lons = latlon_coords(dbz)\n",
    "    \n",
    "    dbz_contours = ax.contourf(to_np(lons), \n",
    "                               to_np(lats), \n",
    "                               to_np(dbz), \n",
    "                               levels=dbz_levels,\n",
    "                               cmap=dbz_map, \n",
    "                               norm=dbz_norm, \n",
    "                               extend=\"max\",\n",
    "                               zorder=3,\n",
    "                               transform=crs.PlateCarree())\n",
    "    \n",
    "    cb = fig.colorbar(dbz_contours, ax=ax, shrink=.9)\n",
    "    \n",
    "    # Set the map bounds\n",
    "    ax.set_xlim(cartopy_xlim(dbz))\n",
    "    ax.set_ylim(cartopy_ylim(dbz))\n",
    "    \n",
    "    return ax.clear()\n",
    "    \n",
    "\n",
    "print (\"Creating animation. This may take a few minutes...\")\n",
    "\n",
    "# This function is called for each frame of the animation, where\n",
    "# i is the frame index. Here is where the animation frames need \n",
    "# to be created.\n",
    "def animate(i):\n",
    "    if (i%9 == 0 and i > 0):\n",
    "        print(\"Completed frame {}...\".format((10*i)//9))\n",
    "        \n",
    "    ax.clear()\n",
    "    \n",
    "    dbz = dbz_all[i,:]\n",
    "    \n",
    "    # Get the lat/lon coordinates\n",
    "    lats, lons = latlon_coords(dbz)\n",
    "    \n",
    "    ax.add_feature(land)\n",
    "    ax.add_feature(states, linewidth=2.0, edgecolor=\"black\", zorder=3)\n",
    "    \n",
    "    dbz_contours = ax.contourf(to_np(lons), \n",
    "                               to_np(lats), \n",
    "                               to_np(dbz),\n",
    "                               levels=dbz_levels,\n",
    "                               cmap=dbz_map, \n",
    "                               norm=dbz_norm,\n",
    "                               extend=\"max\",\n",
    "                               zorder=3,\n",
    "                               transform=crs.PlateCarree()) \n",
    "    \n",
    "    # Set the map bounds\n",
    "    ax.set_xlim(cartopy_xlim(dbz))\n",
    "    ax.set_ylim(cartopy_ylim(dbz))\n",
    "     \n",
    "    return ax\n",
    "\n",
    "# Create the animation by supplying a figure, the animation object, the number of frames,\n",
    "# the init functions, and an interval in milliseconds that is the delay between frames.\n",
    "ani = FuncAnimation(fig, animate, num_frames, init_func=init, interval=500)\n",
    "\n",
    "# To work with jupyter notebook, you need to use the HTML generated\n",
    "# by the HTML function from the IPython.display package.\n",
    "# If you change 'to_jshtml' to be 'to_html5_video', you will get an HTML5 video instead.\n",
    "\n",
    "#HTML(ani.to_html5_video())\n",
    "HTML(ani.to_jshtml())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 7.6: Reducing WRF File Size\n",
    "\n",
    "The WRF files used for this tutorial were originally 10 GB each. To reduce the files sizes, I removed all of the variables that aren't of interest to WRF-Python, cropped the horizontal domain to a smaller region around Idaho, and removed the vertical levels above 400 mb. \n",
    "\n",
    "Until frontend xarray support is added in the future, the only way you can reduce a large WRF data set to a smaller domain is to use a custom interable that crops the domain out and write the files to a temporary location. \n",
    "\n",
    "Below is the iterable class I used for this purpose via WRF-Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, ll_to_xy, CoordPair, GeoBounds, to_np\n",
    "\n",
    "_VARS_TO_KEEP = (\"Times\", \"XLAT\", \"XLONG\", \"XLAT_U\", \"XLAT_V\", \"XLONG_U\", \n",
    "                \"XLONG_V\", \"U\", \"V\", \"W\", \"PH\", \"PHB\", \"T\", \"P\", \"PB\", \"Q2\", \n",
    "                \"T2\", \"PSFC\", \"U10\", \"V10\", \"XTIME\", \"QVAPOR\", \"QCLOUD\", \n",
    "                \"QGRAUP\", \"QRAIN\", \"QSNOW\", \"QICE\", \"MAPFAC_M\", \"MAPFAC_U\",\n",
    "                \"MAPFAC_V\", \"F\", \"HGT\", \"RAINC\", \"RAINSH\", \"RAINNC\", \"I_RAINC\", \"I_RAINNC\")\n",
    "\n",
    "class FileReduce(object):\n",
    "    def __init__(self, filenames, geobounds, tempdir=None, vars_to_keep=None, \n",
    "                 max_pres=None, compress=False, delete=True, reuse=False):\n",
    "        \"\"\"An iterable object for cutting out geographic domains.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            filenames (sequence): A sequence of file paths to the WRF files\n",
    "            \n",
    "            geobounds (GeoBounds): A GeoBounds object defining the region of interest\n",
    "            \n",
    "            tempdir (str): The location to store the temporary cropped data files. If None, tempfile.mkdtemp is used.\n",
    "            \n",
    "            vars_to_keep (sequence): A sequence of variables names to keep from the original file. None for all vars.\n",
    "            \n",
    "            max_press (float): The maximum pressure height level to keep. None for all levels.\n",
    "            \n",
    "            compress(bool): Set to True to enable zlib compression of variables in the output.\n",
    "            \n",
    "            delete (bool): Set to True to delete the temporary directory when FileReduce is garbage collected.\n",
    "            \n",
    "            reuse (bool): Set to True when you want to resuse the files that were previously converted. *tempdir* \n",
    "                must be set to a specific directory that contains the converted files and *delete* must be False.\n",
    "                \n",
    "        \n",
    "        \"\"\"\n",
    "        self._filenames = filenames\n",
    "        self._i = 0\n",
    "        self._geobounds = geobounds\n",
    "        self._delete = delete\n",
    "        self._vars_to_keep = vars_to_keep\n",
    "        self._max_pres = max_pres\n",
    "        self._compress = compress\n",
    "        self._cache = set()\n",
    "        self._own_data = True\n",
    "        self._reuse = reuse\n",
    "        \n",
    "        if tempdir is not None:\n",
    "            if not os.path.exists(tempdir):\n",
    "                os.makedirs(tempdir)\n",
    "            self._tempdir = tempdir\n",
    "            if self._reuse:\n",
    "                self._cache = set((os.path.join(self._tempdir, name) \n",
    "                                   for name in os.listdir(self._tempdir)))\n",
    "        else:\n",
    "            self._tempdir = tempfile.mkdtemp()\n",
    "\n",
    "        self._prev = None\n",
    "        self._set_extents()\n",
    "    \n",
    "    def _set_extents(self):\n",
    "        fname = list(self._filenames)[0]\n",
    "        with Dataset(fname) as ncfile:\n",
    "            lons = [self._geobounds.bottom_left.lon, self._geobounds.top_right.lon]\n",
    "            lats = [self._geobounds.bottom_left.lat, self._geobounds.top_right.lat]\n",
    "            orig_west_east = len(ncfile.dimensions[\"west_east\"])\n",
    "            orig_south_north = len(ncfile.dimensions[\"south_north\"])\n",
    "            orig_bottom_top = len(ncfile.dimensions[\"bottom_top\"])\n",
    "            \n",
    "            # Note: Not handling the moving nest here\n",
    "            # Extra points included around the boundaries to ensure domain is fully included\n",
    "            x_y = ll_to_xy(ncfile, lats, lons, meta=False)\n",
    "            self._start_x = 0 if x_y[0,0] == 0 else x_y[0,0] - 1\n",
    "            self._end_x = orig_west_east - 1 if x_y[0,1] >= orig_west_east - 1 else x_y[0,1] + 1\n",
    "            self._start_y = 0 if x_y[1,0] == 0 else x_y[1,0] - 1\n",
    "            self._end_y = orig_south_north - 1 if x_y[1,1] >= orig_south_north - 1 else x_y[1,1] + 1\n",
    "            \n",
    "            self._west_east = self._end_x - self._start_x + 1\n",
    "            self._west_east_stag = self._west_east + 1\n",
    "            self._south_north = self._end_y - self._start_y + 1\n",
    "            self._south_north_stag = self._south_north + 1\n",
    "            \n",
    "            # Crop the vertical to the specified pressure\n",
    "            if self._max_pres is not None:\n",
    "                pres = getvar(ncfile, \"pressure\")\n",
    "                # Find the lowest terrain height\n",
    "                ter = to_np(getvar(ncfile, \"ter\"))\n",
    "                min_ter = float(np.amin(ter)) + 1\n",
    "                ter_less = ter <= min_ter\n",
    "                ter_less = np.broadcast_to(ter_less, pres.shape)\n",
    "                # For the lowest terrain height, find the lowest vertical index to meet \n",
    "                # the desired pressure level. The lowest terrain height will result in the \n",
    "                # largest vertical spread to find the pressure level.\n",
    "                x = np.transpose(((pres.values <= self._max_pres) & ter_less).nonzero())\n",
    "                self._end_bot_top = np.amin(x, axis=0)[0] \n",
    "                if (self._end_bot_top >= orig_bottom_top):\n",
    "                    self._end_bot_top = orig_bottom_top - 1\n",
    "            else:\n",
    "                self._end_bot_top = orig_bottom_top - 1\n",
    "                \n",
    "            self._bottom_top = self._end_bot_top + 1\n",
    "            self._bottom_top_stag = self._bottom_top + 1\n",
    "            \n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __copy__(self):\n",
    "        cp = type(self).__new__(self.__class__)\n",
    "        cp.__dict__.update(self.__dict__)\n",
    "        cp._own_data = False\n",
    "        cp._delete = False\n",
    "        \n",
    "        return cp\n",
    "    \n",
    "    def __del__(self):\n",
    "        if self._delete:\n",
    "            shutil.rmtree(self._tempdir)\n",
    "    \n",
    "    def reduce(self, fname):\n",
    "        outfilename = os.path.join(self._tempdir, os.path.basename(fname))\n",
    "        \n",
    "        # WRF-Python can iterate over sequences several times during a 'getvar', so a cache is used to \n",
    "        if outfilename in self._cache:\n",
    "            return Dataset(outfilename)\n",
    "        \n",
    "        # New dimension sizes\n",
    "        dim_d = {\"west_east\" : self._west_east,\n",
    "                 \"west_east_stag\" : self._west_east_stag,\n",
    "                 \"south_north\" : self._south_north,\n",
    "                 \"south_north_stag\" : self._south_north_stag,\n",
    "                 \"bottom_top\" : self._bottom_top,\n",
    "                 \"bottom_top_stag\" : self._bottom_top_stag\n",
    "                }\n",
    "        \n",
    "        # Data slice sizes for the 2D dimensions\n",
    "        slice_d = {\"west_east\" : slice(self._start_x, self._end_x + 1),\n",
    "                   \"west_east_stag\" : slice(self._start_x, self._end_x + 2),\n",
    "                   \"south_north\" : slice(self._start_y, self._end_y + 1),\n",
    "                   \"south_north_stag\" : slice(self._start_y, self._end_y + 2),\n",
    "                   \"bottom_top\" : slice(None, self._end_bot_top + 1),\n",
    "                   \"bottom_top_stag\" : slice(None, self._end_bot_top + 2)\n",
    "                  }\n",
    "        \n",
    "        with Dataset(fname) as infile, Dataset(outfilename, mode=\"w\") as outfile:\n",
    "            \n",
    "            # Copy the global attributes\n",
    "            outfile.setncatts(infile.__dict__)\n",
    "\n",
    "            # Copy Dimensions, limiting south_north and west_east to desired domain\n",
    "            for name, dimension in infile.dimensions.items():\n",
    "                dimsize = dim_d.get(name, len(dimension))\n",
    "                outfile.createDimension(name, dimsize)\n",
    "\n",
    "            # Copy Variables  \n",
    "            for name, variable in infile.variables.iteritems():\n",
    "                if self._vars_to_keep is not None:\n",
    "                    if name not in self._vars_to_keep:\n",
    "                        continue\n",
    "                \n",
    "                print (name)\n",
    "                new_slices = tuple((slice_d.get(dimname, slice(None)) for dimname in variable.dimensions))\n",
    "\n",
    "                outvar = outfile.createVariable(name, variable.datatype, variable.dimensions, zlib=self._compress)\n",
    "\n",
    "                outvar[:] = variable[new_slices]\n",
    "\n",
    "                outvar.setncatts(variable.__dict__)\n",
    "                \n",
    "        \n",
    "        result = Dataset(outfilename)\n",
    "            \n",
    "        self._cache.add(outfilename)\n",
    "            \n",
    "        return result\n",
    "            \n",
    "    \n",
    "    def next(self):\n",
    "        if self._i >= len(self._filenames):\n",
    "            if self._prev is not None:\n",
    "                self._prev.close()\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            fname = self._filenames[self._i]\n",
    "            reduced_file = self.reduce(fname)\n",
    "            if self._prev is not None:\n",
    "                self._prev.close()\n",
    "            self._prev = reduced_file\n",
    "            \n",
    "            self._i += 1\n",
    "            \n",
    "            return reduced_file\n",
    "    \n",
    "    # Python 3\n",
    "    def __next__(self):\n",
    "        return self.next()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this with getvar, you would do:\n",
    "\n",
    "``` python\n",
    "\n",
    "# How to use with getvar\n",
    "\n",
    "VARS_TO_KEEP = (\"Times\", \"XLAT\", \"XLONG\", \"XLAT_U\", \"XLAT_V\", \"XLONG_U\", \n",
    "                \"XLONG_V\", \"U\", \"V\", \"W\", \"PH\", \"PHB\", \"T\", \"P\", \"PB\", \"Q2\", \n",
    "                \"T2\", \"PSFC\", \"U10\", \"V10\", \"XTIME\", \"QVAPOR\", \"QCLOUD\", \n",
    "                \"QGRAUP\", \"QRAIN\", \"QSNOW\", \"QICE\", \"MAPFAC_M\", \"MAPFAC_U\",\n",
    "                \"MAPFAC_V\", \"F\", \"HGT\", \"RAINC\", \"RAINSH\", \"RAINNC\", \n",
    "                \"I_RAINC\", \"I_RAINNC\")\n",
    "\n",
    "# Set lower left and upper right to your desired domain\n",
    "# Idaho bounding box: [\"41.9880561828613\",\"49.000846862793\",\"-117.243034362793\",\"-111.043563842773\"]\n",
    "ll = CoordPair(lat=41.8, lon=-117.26)\n",
    "ur = CoordPair(lat=49.1, lon=-110.5)\n",
    "\n",
    "bounds = GeoBounds(ll, ur)\n",
    "\n",
    "reduced_files = FileReduce(glob.glob(\"/path/to/wrfout_d01_*\"),\n",
    "                           bounds, \n",
    "                           vars_to_keep=VARS_TO_KEEP, \n",
    "                           max_pres=400,\n",
    "                           tempdir=\"/path/to/reduced\", \n",
    "                           delete=False, \n",
    "                           reuse=True)\n",
    "\n",
    "pres = getvar(reduced_files, \"pressure\")\n",
    "\n",
    "```\n",
    "\n",
    "Note that by setting 'reuse=True', the second time your run this, it will use the already cropped files, so you only pay the cropping penalty once."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
